{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pydicom\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(image, angle):\n",
    "    return np.rot90(image, k=angle // 90)\n",
    "\n",
    "def flip_image(image):\n",
    "    return np.fliplr(image)\n",
    "\n",
    "def rotate_and_flip_masks(masks, angle):\n",
    "    rotated_masks = [rotate_image(mask, angle) for mask in masks]\n",
    "    flipped_masks = [flip_image(mask) for mask in rotated_masks]\n",
    "    return np.array(flipped_masks)\n",
    "\n",
    "# Função para carregar imagens DICOM\n",
    "def load_dicom_images(folder_path):\n",
    "    images = []\n",
    "    files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".dcm\")])\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        dicom = pydicom.dcmread(file_path)\n",
    "        image = dicom.pixel_array\n",
    "        images.append(image)\n",
    "    return np.array(images)\n",
    "\n",
    "# Função para carregar máscaras NIfTI\n",
    "def load_nifti_masks(folder_path):\n",
    "    masks = []\n",
    "    files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".nii.gz\")])\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        print(f'Carregando arquivo: {file_path}')  # Log\n",
    "        try:\n",
    "            nifti_img = nib.load(file_path)\n",
    "            mask_volume = nifti_img.get_fdata()\n",
    "            if mask_volume.size == 0:\n",
    "                print(f'Arquivo vazio: {file_path}')  # Log\n",
    "            else:\n",
    "                # Separar as fatias individuais do volume 3D\n",
    "                for i in range(mask_volume.shape[-1]):\n",
    "                    masks.append(mask_volume[:, :, i])\n",
    "        except Exception as e:\n",
    "            print(f'Erro ao carregar {file_path}: {e}')  # Log\n",
    "    return np.array(masks)\n",
    "\n",
    "def preprocess_images(images, target_size=(128, 128)):\n",
    "    images = images / np.max(images)  # Normalização\n",
    "    images = np.expand_dims(images, axis=-1)  # Adiciona canal de cor\n",
    "    images_resized = np.array([tf.image.resize(image, target_size).numpy() for image in images])\n",
    "    return images_resized\n",
    "\n",
    "def preprocess_masks(masks, target_size=(128, 128)):\n",
    "    masks = np.expand_dims(masks, axis=-1)  # Adiciona canal de cor\n",
    "    masks_resized = np.array([tf.image.resize(mask, target_size).numpy() for mask in masks])\n",
    "    return masks_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred)\n",
    "    return 1 - numerator / denominator\n",
    "\n",
    "# Carregar o modelo salvo\n",
    "model = load_model('C:/Users/nicol/OneDrive/Documentos/PDI-Final-Article/unet_model3.keras', \n",
    "                   custom_objects={'dice_loss': dice_loss},\n",
    "                   compile=False)\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss=dice_loss,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Função para carregar e pré-processar dados (sem máscaras)\n",
    "def load_and_preprocess_images(image_folder_path, target_size=(128, 128)):\n",
    "    images = load_dicom_images(image_folder_path)\n",
    "    images_preprocessed = preprocess_images(images, target_size)\n",
    "    return images_preprocessed\n",
    "\n",
    "# Carregar e pré-processar dados de exam03\n",
    "image_folder_path_exam03 = 'C:/Users/nicol/OneDrive/Documentos/PDI-Final-Article/dataset/exam01/data'\n",
    "images_exam03 = load_and_preprocess_images(image_folder_path_exam03)\n",
    "\n",
    "# Fazer previsões nas imagens de exam03\n",
    "predictions_exam03 = model.predict(images_exam03)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def plot_predictions(images, predictions, num_images_per_page=5):\n",
    "    num_pages = math.ceil(len(images) / num_images_per_page)\n",
    "    \n",
    "    for page in range(num_pages):\n",
    "        start_idx = page * num_images_per_page\n",
    "        end_idx = min((page + 1) * num_images_per_page, len(images))\n",
    "        \n",
    "        plt.figure(figsize=(20, 10))\n",
    "        for i in range(start_idx, end_idx):\n",
    "            plt.subplot(2, num_images_per_page, i - start_idx + 1)\n",
    "            plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "            plt.title('Original Image')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(2, num_images_per_page, i - start_idx + 1 + num_images_per_page)\n",
    "            plt.imshow(predictions[i].squeeze(), cmap='gray')\n",
    "            plt.title('Predicted Mask')\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "# Plotar as previsões para as primeiras 5 imagens\n",
    "plot_predictions(images_exam03, predictions_exam03, num_images_per_page=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def post_process_masks(predictions, threshold=0.5, kernel_size=5, small_object_size=50, small_hole_size=50):\n",
    "    processed_masks = []\n",
    "    \n",
    "    for mask in predictions:\n",
    "        # Aplicar threshold\n",
    "        _, thresholded = cv2.threshold(mask, threshold, 1, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Converter para uint8 para operações morfológicas\n",
    "        thresholded = (thresholded * 255).astype(np.uint8)\n",
    "        \n",
    "        # Criar kernel para operações morfológicas\n",
    "        kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "        \n",
    "        # Aplicar abertura para remover ruídos pequenos\n",
    "        opened = cv2.morphologyEx(thresholded, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "        \n",
    "        # Aplicar fechamento para remover pequenos buracos\n",
    "        closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "        \n",
    "        # Remover objetos pequenos\n",
    "        nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(closed, connectivity=8)\n",
    "        sizes = stats[1:, -1]\n",
    "        nb_components = nb_components - 1\n",
    "        img_without_small_objects = np.zeros((output.shape))\n",
    "        for i in range(0, nb_components):\n",
    "            if sizes[i] >= small_object_size:\n",
    "                img_without_small_objects[output == i + 1] = 255\n",
    "        \n",
    "        # Preencher pequenos buracos\n",
    "        img_without_small_holes = img_without_small_objects.copy()\n",
    "        contours, _ = cv2.findContours(img_without_small_objects.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area < small_hole_size:\n",
    "                cv2.drawContours(img_without_small_holes, [cnt], 0, (255), -1)\n",
    "        \n",
    "        # Normalizar de volta para o intervalo [0, 1]\n",
    "        processed = img_without_small_holes.astype(float) / 255.0\n",
    "        \n",
    "        processed_masks.append(processed)\n",
    "    \n",
    "    return np.array(processed_masks)\n",
    "\n",
    "\n",
    "# Aplicar pós-processamento às máscaras previstas\n",
    "processed_predictions = post_process_masks(predictions_exam03)\n",
    "\n",
    "# Função para plotar as imagens originais, previsões e máscaras pós-processadas\n",
    "def plot_predictions_and_processed(images, predictions, processed, num_images_per_page=5):\n",
    "    num_pages = math.ceil(len(images) / num_images_per_page)\n",
    "    \n",
    "    for page in range():\n",
    "        start_idx = page * num_images_per_page\n",
    "        end_idx = min((page + 1) * num_images_per_page, len(images))\n",
    "        \n",
    "        plt.figure(figsize=(20, 15))\n",
    "        for i in range(start_idx, end_idx):\n",
    "            plt.subplot(3, num_images_per_page, i - start_idx + 1)\n",
    "            plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "            plt.title('Original Image')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(3, num_images_per_page, i - start_idx + 1 + num_images_per_page)\n",
    "            plt.imshow(predictions[i].squeeze(), cmap='gray')\n",
    "            plt.title('Predicted Mask')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(3, num_images_per_page, i - start_idx + 1 + 2*num_images_per_page)\n",
    "            plt.imshow(processed[i].squeeze(), cmap='gray')\n",
    "            plt.title('Processed Mask')\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Plotar as imagens originais, previsões e máscaras pós-processadas\n",
    "plot_predictions_and_processed(images_exam03, predictions_exam03, processed_predictions, num_images_per_page=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
